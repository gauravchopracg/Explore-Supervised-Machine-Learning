{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Explore Supervised Machine Learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VGeHTkd9IGV",
        "colab_type": "text"
      },
      "source": [
        "To Explore Supervised Machine Learning:\n",
        "===\n",
        "In this task, we will try to understand supervised machine learning through regression i.e., by predicting the precentage of marks that a student is expected to score based upon the number of hours they studied. \n",
        "\n",
        "**This is a simple linear regression task as it involves just two variables.**\n",
        "\n",
        "We will approach this in two way: firstly by performing linear regression from scratch using numpy and then implementing linear regression with Scikit Learn ( a much advance library for machine learning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W962xdqU_FAT",
        "colab_type": "text"
      },
      "source": [
        "Part I:\n",
        "---\n",
        "In this part we will create an end-2-end pipeline in numpy to find the line of best fit on the relationship between the percentage of marks and number of hours a student has studied by using vanilla gradient descent. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faXZJgdgwUxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd # for reading csv file and data manipulation\n",
        "import numpy as np # for performing scientific and mathematical operations\n",
        "import matplotlib.pyplot as plt # for visualizing the relationship between data\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzRSi6TVANp4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "81a90314-5e5d-4531-bd44-995d467f80ee"
      },
      "source": [
        "data = pd.read_csv('http://bit.ly/w-data') # read the data\n",
        "data.head() # take a look at it"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Hours</th>\n",
              "      <th>Scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.5</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.1</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.2</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.5</td>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.5</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Hours  Scores\n",
              "0    2.5      21\n",
              "1    5.1      47\n",
              "2    3.2      27\n",
              "3    8.5      75\n",
              "4    3.5      30"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alwfC529AtVn",
        "colab_type": "text"
      },
      "source": [
        "**We have two quantities in our dataset we will transform in the form of numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vk76OG5AXcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d5693c3-f24b-4d76-a936-74e3e967e07a"
      },
      "source": [
        "x = data.Hours.values\n",
        "y = data.Scores.values\n",
        "\n",
        "x.shape, y.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25,), (25,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8uB-dzoC_OD",
        "colab_type": "text"
      },
      "source": [
        "Now, we will try to fit a straight line based on this equation: $y = mx + c$. To do that we will first initialize slope ($m$) and intercept ($c$) as zero\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q1cX9niD255",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = 0 # initialize slope as 0\n",
        "c = 0 # initialize intercept as 0\n",
        "\n",
        "y_pred = np.zeros(x.shape) # initialize predictions scores as zero\n",
        "# loop through every student study hours\n",
        "for i in range(len(x)):\n",
        "  # calculate the prediction value for each student and store them\n",
        "  y_pred[i] = c+m*x[i]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfnJz41UELO2",
        "colab_type": "text"
      },
      "source": [
        "and then, we will calculate the error between prediction and true values using sum of squares error as known also Mean Square Error (MSE):\n",
        "\n",
        "\\begin{equation*}\n",
        "MSE = \\frac{1}{n}\\sum(y - \\hat y)^2\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YykJciZ4BBE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "error = 0 # initialize error as zero\n",
        "# iterate through every prediction and true value\n",
        "for i in range(len(y_pred)):\n",
        "  # calculate the difference between true value and predicted value\n",
        "  difference = y_pred[i] - y[i]\n",
        "  # square the difference\n",
        "  square = difference**2\n",
        "  # append the error for every prediction\n",
        "  error += square\n",
        "  \n",
        "# normalize it by dividing it through number of students\n",
        "error /= float(len(y_pred))  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0Sk0I3GHuyP",
        "colab_type": "text"
      },
      "source": [
        "Let's take a look at the initial error:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrk0QTGiHkpo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceb03270-cff0-450e-ada2-20bda47b5779"
      },
      "source": [
        "error"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3264.04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VXY3evjH00g",
        "colab_type": "text"
      },
      "source": [
        "It's time to reduce it by using optimization algorithm, we will implement vanilla gradient descent to do so. Let's go through a single iteration step by step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-Coj9mkH-U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameter\n",
        "learning_rate = 0.0001 # how fast and slow we want to update slope and intercept"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Roi32YUqQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dc = 0 # derivate of error with respect to intercept\n",
        "dm = 0 # derivate of error with respect to slope\n",
        "N = float(len(x)) # number of students\n",
        "# iterate through every student\n",
        "for i in range(int(N)):\n",
        "  x_i = x[i] # number of hour a student has studied\n",
        "  y_i = y[i] # number of marks a student has scored\n",
        "  y_pred_i = y_pred[i]\n",
        "  dc += -(2/N) * (y_i - y_pred_i)\n",
        "  dm += -(2/N) * (y_i - y_pred_i) * x_i\n",
        "\n",
        "# update weigths\n",
        "c = c - (learning_rate*dc)\n",
        "m = m - (learning_rate*dm)\n",
        "\n",
        "y_pred = np.zeros(x.shape) # initialize predictions scores as zero\n",
        "# loop through every student study hours\n",
        "for i in range(len(x)):\n",
        "  # calculate the prediction value for each student and store them\n",
        "  y_pred[i] = c+m*x[i]\n",
        "\n",
        "error = 0 # initialize error as zero\n",
        "# iterate through every prediction and true value\n",
        "for i in range(len(y_pred)):\n",
        "  # calculate the difference between true value and predicted value\n",
        "  difference = y_pred[i] - y[i]\n",
        "  # square the difference\n",
        "  square = difference**2\n",
        "  # append the error for every prediction\n",
        "  error += square\n",
        "  \n",
        "# normalize it by dividing it through number of students\n",
        "error /= float(len(y_pred))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0BMSTZuWe0Y",
        "colab_type": "text"
      },
      "source": [
        "Let's see if error is reduced or not"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q19oO3izWb3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "834a8de2-6ec5-46ac-e458-db49c3b2d68a"
      },
      "source": [
        "error"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3222.699871135168"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TNTqoaMWqM1",
        "colab_type": "text"
      },
      "source": [
        "**It works, Now we can go through a number of iteration and find the line of best fit. We will create python functions to do so**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaAzeqgpQqeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initial_parameter(c, m):\n",
        "  '''\n",
        "  Initialize paramters for model to learn\n",
        "  '''\n",
        "  return c, m\n",
        "\n",
        "def f(c, m, X):\n",
        "  y = np.zeros(X.shape[0])\n",
        "  for i in range(len(X)):\n",
        "    y[i] = c + m*X[i]\n",
        "  return y\n",
        "\n",
        "def calculate_error(y_pred, y):\n",
        "  '''\n",
        "  sum of squared errors\n",
        "  '''\n",
        "  errors = 0\n",
        "  for i in range(0, len(y_pred)):\n",
        "    difference = y_pred[i]-y[i] # for every point\n",
        "    square = difference**2\n",
        "    errors += square\n",
        "  return errors/float(len(y_pred))\n",
        "\n",
        "def update(X, Y, c, m, learning_rate):\n",
        "  dc = 0 # derivate of error with respect to intercept\n",
        "  dm = 0 # derivate of error with respect to slope\n",
        "  N = float(len(X))\n",
        "  Y_pred = np.zeros(Y.shape)\n",
        "  for i in range(int(N)):\n",
        "    Y_pred[i] = c+m*X[i]\n",
        "  for i in range(0, int(N)):\n",
        "    x = X[i] # x-point\n",
        "    y = Y[i] # y-point\n",
        "    y_pre = Y_pred[i]\n",
        "    dc += -(2/N) * (y-y_pre) # update dE/dc gradient\n",
        "    dm += -(2/N) * x * (y-y_pre) # update dE/dm gradient\n",
        "  # update weights\n",
        "  c = c - (learning_rate*dc)\n",
        "  m = m - (learning_rate*dm)\n",
        "  return c, m"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aTQdh7gR76H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1f3c134c-14f0-4c91-b04a-fd3c1d3fb683"
      },
      "source": [
        "num_iterations = 400\n",
        "learning_rate = 0.0001\n",
        "\n",
        "for i in range(num_iterations):\n",
        "  c, m = update(x, y, c, m, learning_rate)\n",
        "  y_pred = f(c, m, x)\n",
        "  error = calculate_error(y_pred, y)\n",
        "  print(\"Iteration: %d, error: %0.5f\" % (i, error))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0, error: 3181.88803\n",
            "Iteration: 1, error: 3141.59772\n",
            "Iteration: 2, error: 3101.82228\n",
            "Iteration: 3, error: 3062.55513\n",
            "Iteration: 4, error: 3023.78977\n",
            "Iteration: 5, error: 2985.51980\n",
            "Iteration: 6, error: 2947.73888\n",
            "Iteration: 7, error: 2910.44076\n",
            "Iteration: 8, error: 2873.61928\n",
            "Iteration: 9, error: 2837.26833\n",
            "Iteration: 10, error: 2801.38192\n",
            "Iteration: 11, error: 2765.95409\n",
            "Iteration: 12, error: 2730.97900\n",
            "Iteration: 13, error: 2696.45085\n",
            "Iteration: 14, error: 2662.36394\n",
            "Iteration: 15, error: 2628.71263\n",
            "Iteration: 16, error: 2595.49135\n",
            "Iteration: 17, error: 2562.69460\n",
            "Iteration: 18, error: 2530.31696\n",
            "Iteration: 19, error: 2498.35307\n",
            "Iteration: 20, error: 2466.79765\n",
            "Iteration: 21, error: 2435.64547\n",
            "Iteration: 22, error: 2404.89139\n",
            "Iteration: 23, error: 2374.53032\n",
            "Iteration: 24, error: 2344.55723\n",
            "Iteration: 25, error: 2314.96717\n",
            "Iteration: 26, error: 2285.75523\n",
            "Iteration: 27, error: 2256.91660\n",
            "Iteration: 28, error: 2228.44649\n",
            "Iteration: 29, error: 2200.34021\n",
            "Iteration: 30, error: 2172.59309\n",
            "Iteration: 31, error: 2145.20056\n",
            "Iteration: 32, error: 2118.15807\n",
            "Iteration: 33, error: 2091.46116\n",
            "Iteration: 34, error: 2065.10541\n",
            "Iteration: 35, error: 2039.08646\n",
            "Iteration: 36, error: 2013.40000\n",
            "Iteration: 37, error: 1988.04179\n",
            "Iteration: 38, error: 1963.00764\n",
            "Iteration: 39, error: 1938.29339\n",
            "Iteration: 40, error: 1913.89497\n",
            "Iteration: 41, error: 1889.80834\n",
            "Iteration: 42, error: 1866.02950\n",
            "Iteration: 43, error: 1842.55454\n",
            "Iteration: 44, error: 1819.37957\n",
            "Iteration: 45, error: 1796.50074\n",
            "Iteration: 46, error: 1773.91429\n",
            "Iteration: 47, error: 1751.61647\n",
            "Iteration: 48, error: 1729.60359\n",
            "Iteration: 49, error: 1707.87201\n",
            "Iteration: 50, error: 1686.41814\n",
            "Iteration: 51, error: 1665.23843\n",
            "Iteration: 52, error: 1644.32938\n",
            "Iteration: 53, error: 1623.68752\n",
            "Iteration: 54, error: 1603.30944\n",
            "Iteration: 55, error: 1583.19178\n",
            "Iteration: 56, error: 1563.33120\n",
            "Iteration: 57, error: 1543.72442\n",
            "Iteration: 58, error: 1524.36819\n",
            "Iteration: 59, error: 1505.25931\n",
            "Iteration: 60, error: 1486.39463\n",
            "Iteration: 61, error: 1467.77102\n",
            "Iteration: 62, error: 1449.38540\n",
            "Iteration: 63, error: 1431.23473\n",
            "Iteration: 64, error: 1413.31600\n",
            "Iteration: 65, error: 1395.62626\n",
            "Iteration: 66, error: 1378.16258\n",
            "Iteration: 67, error: 1360.92206\n",
            "Iteration: 68, error: 1343.90187\n",
            "Iteration: 69, error: 1327.09917\n",
            "Iteration: 70, error: 1310.51119\n",
            "Iteration: 71, error: 1294.13519\n",
            "Iteration: 72, error: 1277.96846\n",
            "Iteration: 73, error: 1262.00833\n",
            "Iteration: 74, error: 1246.25215\n",
            "Iteration: 75, error: 1230.69731\n",
            "Iteration: 76, error: 1215.34126\n",
            "Iteration: 77, error: 1200.18143\n",
            "Iteration: 78, error: 1185.21534\n",
            "Iteration: 79, error: 1170.44049\n",
            "Iteration: 80, error: 1155.85445\n",
            "Iteration: 81, error: 1141.45481\n",
            "Iteration: 82, error: 1127.23918\n",
            "Iteration: 83, error: 1113.20522\n",
            "Iteration: 84, error: 1099.35059\n",
            "Iteration: 85, error: 1085.67301\n",
            "Iteration: 86, error: 1072.17021\n",
            "Iteration: 87, error: 1058.83997\n",
            "Iteration: 88, error: 1045.68008\n",
            "Iteration: 89, error: 1032.68835\n",
            "Iteration: 90, error: 1019.86265\n",
            "Iteration: 91, error: 1007.20084\n",
            "Iteration: 92, error: 994.70084\n",
            "Iteration: 93, error: 982.36058\n",
            "Iteration: 94, error: 970.17801\n",
            "Iteration: 95, error: 958.15113\n",
            "Iteration: 96, error: 946.27794\n",
            "Iteration: 97, error: 934.55647\n",
            "Iteration: 98, error: 922.98479\n",
            "Iteration: 99, error: 911.56099\n",
            "Iteration: 100, error: 900.28317\n",
            "Iteration: 101, error: 889.14947\n",
            "Iteration: 102, error: 878.15805\n",
            "Iteration: 103, error: 867.30708\n",
            "Iteration: 104, error: 856.59478\n",
            "Iteration: 105, error: 846.01938\n",
            "Iteration: 106, error: 835.57911\n",
            "Iteration: 107, error: 825.27226\n",
            "Iteration: 108, error: 815.09713\n",
            "Iteration: 109, error: 805.05202\n",
            "Iteration: 110, error: 795.13528\n",
            "Iteration: 111, error: 785.34526\n",
            "Iteration: 112, error: 775.68035\n",
            "Iteration: 113, error: 766.13895\n",
            "Iteration: 114, error: 756.71947\n",
            "Iteration: 115, error: 747.42037\n",
            "Iteration: 116, error: 738.24010\n",
            "Iteration: 117, error: 729.17715\n",
            "Iteration: 118, error: 720.23001\n",
            "Iteration: 119, error: 711.39721\n",
            "Iteration: 120, error: 702.67728\n",
            "Iteration: 121, error: 694.06878\n",
            "Iteration: 122, error: 685.57029\n",
            "Iteration: 123, error: 677.18040\n",
            "Iteration: 124, error: 668.89773\n",
            "Iteration: 125, error: 660.72090\n",
            "Iteration: 126, error: 652.64856\n",
            "Iteration: 127, error: 644.67938\n",
            "Iteration: 128, error: 636.81203\n",
            "Iteration: 129, error: 629.04523\n",
            "Iteration: 130, error: 621.37767\n",
            "Iteration: 131, error: 613.80810\n",
            "Iteration: 132, error: 606.33526\n",
            "Iteration: 133, error: 598.95792\n",
            "Iteration: 134, error: 591.67485\n",
            "Iteration: 135, error: 584.48485\n",
            "Iteration: 136, error: 577.38673\n",
            "Iteration: 137, error: 570.37931\n",
            "Iteration: 138, error: 563.46145\n",
            "Iteration: 139, error: 556.63199\n",
            "Iteration: 140, error: 549.88980\n",
            "Iteration: 141, error: 543.23377\n",
            "Iteration: 142, error: 536.66280\n",
            "Iteration: 143, error: 530.17580\n",
            "Iteration: 144, error: 523.77169\n",
            "Iteration: 145, error: 517.44942\n",
            "Iteration: 146, error: 511.20795\n",
            "Iteration: 147, error: 505.04623\n",
            "Iteration: 148, error: 498.96326\n",
            "Iteration: 149, error: 492.95802\n",
            "Iteration: 150, error: 487.02952\n",
            "Iteration: 151, error: 481.17678\n",
            "Iteration: 152, error: 475.39883\n",
            "Iteration: 153, error: 469.69472\n",
            "Iteration: 154, error: 464.06350\n",
            "Iteration: 155, error: 458.50424\n",
            "Iteration: 156, error: 453.01603\n",
            "Iteration: 157, error: 447.59794\n",
            "Iteration: 158, error: 442.24910\n",
            "Iteration: 159, error: 436.96861\n",
            "Iteration: 160, error: 431.75559\n",
            "Iteration: 161, error: 426.60920\n",
            "Iteration: 162, error: 421.52857\n",
            "Iteration: 163, error: 416.51286\n",
            "Iteration: 164, error: 411.56125\n",
            "Iteration: 165, error: 406.67292\n",
            "Iteration: 166, error: 401.84705\n",
            "Iteration: 167, error: 397.08286\n",
            "Iteration: 168, error: 392.37955\n",
            "Iteration: 169, error: 387.73633\n",
            "Iteration: 170, error: 383.15246\n",
            "Iteration: 171, error: 378.62716\n",
            "Iteration: 172, error: 374.15969\n",
            "Iteration: 173, error: 369.74931\n",
            "Iteration: 174, error: 365.39529\n",
            "Iteration: 175, error: 361.09691\n",
            "Iteration: 176, error: 356.85346\n",
            "Iteration: 177, error: 352.66424\n",
            "Iteration: 178, error: 348.52855\n",
            "Iteration: 179, error: 344.44571\n",
            "Iteration: 180, error: 340.41504\n",
            "Iteration: 181, error: 336.43588\n",
            "Iteration: 182, error: 332.50758\n",
            "Iteration: 183, error: 328.62947\n",
            "Iteration: 184, error: 324.80092\n",
            "Iteration: 185, error: 321.02129\n",
            "Iteration: 186, error: 317.28996\n",
            "Iteration: 187, error: 313.60632\n",
            "Iteration: 188, error: 309.96975\n",
            "Iteration: 189, error: 306.37965\n",
            "Iteration: 190, error: 302.83543\n",
            "Iteration: 191, error: 299.33650\n",
            "Iteration: 192, error: 295.88228\n",
            "Iteration: 193, error: 292.47221\n",
            "Iteration: 194, error: 289.10571\n",
            "Iteration: 195, error: 285.78223\n",
            "Iteration: 196, error: 282.50122\n",
            "Iteration: 197, error: 279.26214\n",
            "Iteration: 198, error: 276.06445\n",
            "Iteration: 199, error: 272.90763\n",
            "Iteration: 200, error: 269.79115\n",
            "Iteration: 201, error: 266.71449\n",
            "Iteration: 202, error: 263.67715\n",
            "Iteration: 203, error: 260.67862\n",
            "Iteration: 204, error: 257.71841\n",
            "Iteration: 205, error: 254.79603\n",
            "Iteration: 206, error: 251.91099\n",
            "Iteration: 207, error: 249.06282\n",
            "Iteration: 208, error: 246.25105\n",
            "Iteration: 209, error: 243.47521\n",
            "Iteration: 210, error: 240.73484\n",
            "Iteration: 211, error: 238.02949\n",
            "Iteration: 212, error: 235.35871\n",
            "Iteration: 213, error: 232.72207\n",
            "Iteration: 214, error: 230.11911\n",
            "Iteration: 215, error: 227.54942\n",
            "Iteration: 216, error: 225.01257\n",
            "Iteration: 217, error: 222.50813\n",
            "Iteration: 218, error: 220.03570\n",
            "Iteration: 219, error: 217.59486\n",
            "Iteration: 220, error: 215.18522\n",
            "Iteration: 221, error: 212.80637\n",
            "Iteration: 222, error: 210.45791\n",
            "Iteration: 223, error: 208.13947\n",
            "Iteration: 224, error: 205.85065\n",
            "Iteration: 225, error: 203.59109\n",
            "Iteration: 226, error: 201.36040\n",
            "Iteration: 227, error: 199.15821\n",
            "Iteration: 228, error: 196.98417\n",
            "Iteration: 229, error: 194.83790\n",
            "Iteration: 230, error: 192.71907\n",
            "Iteration: 231, error: 190.62731\n",
            "Iteration: 232, error: 188.56228\n",
            "Iteration: 233, error: 186.52364\n",
            "Iteration: 234, error: 184.51105\n",
            "Iteration: 235, error: 182.52419\n",
            "Iteration: 236, error: 180.56271\n",
            "Iteration: 237, error: 178.62629\n",
            "Iteration: 238, error: 176.71462\n",
            "Iteration: 239, error: 174.82739\n",
            "Iteration: 240, error: 172.96426\n",
            "Iteration: 241, error: 171.12495\n",
            "Iteration: 242, error: 169.30914\n",
            "Iteration: 243, error: 167.51654\n",
            "Iteration: 244, error: 165.74684\n",
            "Iteration: 245, error: 163.99975\n",
            "Iteration: 246, error: 162.27500\n",
            "Iteration: 247, error: 160.57228\n",
            "Iteration: 248, error: 158.89132\n",
            "Iteration: 249, error: 157.23185\n",
            "Iteration: 250, error: 155.59358\n",
            "Iteration: 251, error: 153.97624\n",
            "Iteration: 252, error: 152.37957\n",
            "Iteration: 253, error: 150.80331\n",
            "Iteration: 254, error: 149.24719\n",
            "Iteration: 255, error: 147.71095\n",
            "Iteration: 256, error: 146.19435\n",
            "Iteration: 257, error: 144.69713\n",
            "Iteration: 258, error: 143.21904\n",
            "Iteration: 259, error: 141.75983\n",
            "Iteration: 260, error: 140.31928\n",
            "Iteration: 261, error: 138.89713\n",
            "Iteration: 262, error: 137.49316\n",
            "Iteration: 263, error: 136.10713\n",
            "Iteration: 264, error: 134.73881\n",
            "Iteration: 265, error: 133.38797\n",
            "Iteration: 266, error: 132.05440\n",
            "Iteration: 267, error: 130.73787\n",
            "Iteration: 268, error: 129.43817\n",
            "Iteration: 269, error: 128.15507\n",
            "Iteration: 270, error: 126.88837\n",
            "Iteration: 271, error: 125.63785\n",
            "Iteration: 272, error: 124.40332\n",
            "Iteration: 273, error: 123.18456\n",
            "Iteration: 274, error: 121.98138\n",
            "Iteration: 275, error: 120.79357\n",
            "Iteration: 276, error: 119.62094\n",
            "Iteration: 277, error: 118.46329\n",
            "Iteration: 278, error: 117.32044\n",
            "Iteration: 279, error: 116.19220\n",
            "Iteration: 280, error: 115.07837\n",
            "Iteration: 281, error: 113.97877\n",
            "Iteration: 282, error: 112.89323\n",
            "Iteration: 283, error: 111.82155\n",
            "Iteration: 284, error: 110.76358\n",
            "Iteration: 285, error: 109.71912\n",
            "Iteration: 286, error: 108.68801\n",
            "Iteration: 287, error: 107.67007\n",
            "Iteration: 288, error: 106.66515\n",
            "Iteration: 289, error: 105.67306\n",
            "Iteration: 290, error: 104.69366\n",
            "Iteration: 291, error: 103.72677\n",
            "Iteration: 292, error: 102.77223\n",
            "Iteration: 293, error: 101.82989\n",
            "Iteration: 294, error: 100.89960\n",
            "Iteration: 295, error: 99.98119\n",
            "Iteration: 296, error: 99.07452\n",
            "Iteration: 297, error: 98.17944\n",
            "Iteration: 298, error: 97.29579\n",
            "Iteration: 299, error: 96.42343\n",
            "Iteration: 300, error: 95.56223\n",
            "Iteration: 301, error: 94.71202\n",
            "Iteration: 302, error: 93.87269\n",
            "Iteration: 303, error: 93.04408\n",
            "Iteration: 304, error: 92.22605\n",
            "Iteration: 305, error: 91.41848\n",
            "Iteration: 306, error: 90.62123\n",
            "Iteration: 307, error: 89.83417\n",
            "Iteration: 308, error: 89.05717\n",
            "Iteration: 309, error: 88.29009\n",
            "Iteration: 310, error: 87.53282\n",
            "Iteration: 311, error: 86.78522\n",
            "Iteration: 312, error: 86.04718\n",
            "Iteration: 313, error: 85.31857\n",
            "Iteration: 314, error: 84.59927\n",
            "Iteration: 315, error: 83.88916\n",
            "Iteration: 316, error: 83.18813\n",
            "Iteration: 317, error: 82.49605\n",
            "Iteration: 318, error: 81.81282\n",
            "Iteration: 319, error: 81.13832\n",
            "Iteration: 320, error: 80.47244\n",
            "Iteration: 321, error: 79.81507\n",
            "Iteration: 322, error: 79.16610\n",
            "Iteration: 323, error: 78.52542\n",
            "Iteration: 324, error: 77.89292\n",
            "Iteration: 325, error: 77.26851\n",
            "Iteration: 326, error: 76.65208\n",
            "Iteration: 327, error: 76.04353\n",
            "Iteration: 328, error: 75.44276\n",
            "Iteration: 329, error: 74.84966\n",
            "Iteration: 330, error: 74.26414\n",
            "Iteration: 331, error: 73.68610\n",
            "Iteration: 332, error: 73.11545\n",
            "Iteration: 333, error: 72.55209\n",
            "Iteration: 334, error: 71.99593\n",
            "Iteration: 335, error: 71.44687\n",
            "Iteration: 336, error: 70.90484\n",
            "Iteration: 337, error: 70.36973\n",
            "Iteration: 338, error: 69.84145\n",
            "Iteration: 339, error: 69.31993\n",
            "Iteration: 340, error: 68.80508\n",
            "Iteration: 341, error: 68.29680\n",
            "Iteration: 342, error: 67.79501\n",
            "Iteration: 343, error: 67.29964\n",
            "Iteration: 344, error: 66.81060\n",
            "Iteration: 345, error: 66.32781\n",
            "Iteration: 346, error: 65.85119\n",
            "Iteration: 347, error: 65.38066\n",
            "Iteration: 348, error: 64.91614\n",
            "Iteration: 349, error: 64.45756\n",
            "Iteration: 350, error: 64.00484\n",
            "Iteration: 351, error: 63.55790\n",
            "Iteration: 352, error: 63.11667\n",
            "Iteration: 353, error: 62.68108\n",
            "Iteration: 354, error: 62.25106\n",
            "Iteration: 355, error: 61.82654\n",
            "Iteration: 356, error: 61.40743\n",
            "Iteration: 357, error: 60.99369\n",
            "Iteration: 358, error: 60.58523\n",
            "Iteration: 359, error: 60.18199\n",
            "Iteration: 360, error: 59.78390\n",
            "Iteration: 361, error: 59.39090\n",
            "Iteration: 362, error: 59.00293\n",
            "Iteration: 363, error: 58.61991\n",
            "Iteration: 364, error: 58.24178\n",
            "Iteration: 365, error: 57.86849\n",
            "Iteration: 366, error: 57.49997\n",
            "Iteration: 367, error: 57.13615\n",
            "Iteration: 368, error: 56.77699\n",
            "Iteration: 369, error: 56.42241\n",
            "Iteration: 370, error: 56.07237\n",
            "Iteration: 371, error: 55.72680\n",
            "Iteration: 372, error: 55.38564\n",
            "Iteration: 373, error: 55.04885\n",
            "Iteration: 374, error: 54.71635\n",
            "Iteration: 375, error: 54.38811\n",
            "Iteration: 376, error: 54.06406\n",
            "Iteration: 377, error: 53.74415\n",
            "Iteration: 378, error: 53.42833\n",
            "Iteration: 379, error: 53.11655\n",
            "Iteration: 380, error: 52.80875\n",
            "Iteration: 381, error: 52.50488\n",
            "Iteration: 382, error: 52.20490\n",
            "Iteration: 383, error: 51.90875\n",
            "Iteration: 384, error: 51.61638\n",
            "Iteration: 385, error: 51.32775\n",
            "Iteration: 386, error: 51.04281\n",
            "Iteration: 387, error: 50.76151\n",
            "Iteration: 388, error: 50.48380\n",
            "Iteration: 389, error: 50.20965\n",
            "Iteration: 390, error: 49.93899\n",
            "Iteration: 391, error: 49.67180\n",
            "Iteration: 392, error: 49.40801\n",
            "Iteration: 393, error: 49.14760\n",
            "Iteration: 394, error: 48.89052\n",
            "Iteration: 395, error: 48.63672\n",
            "Iteration: 396, error: 48.38617\n",
            "Iteration: 397, error: 48.13882\n",
            "Iteration: 398, error: 47.89462\n",
            "Iteration: 399, error: 47.65355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUsz3kLLX8CT",
        "colab_type": "text"
      },
      "source": [
        "As, we can see that MSE started from 3181.88803 and reduced to 47.65355. Let's take a look at the value of intercept and slope"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae02qR5HI2zX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a62dcc3-7415-48d7-b3ba-d6182dcb594f"
      },
      "source": [
        "print(c, m)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4929174055007548 9.163594975899898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DO7bJgdiHLZ",
        "colab_type": "text"
      },
      "source": [
        "We can further plot the line to see if it fits to the points"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgVjaUj2RkFS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "b8ab8ed2-f943-46eb-92c6-45df760d9d25"
      },
      "source": [
        "pred = f(c, m, x)\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.plot(x, pred, color='blue', linewidth=3)\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "plt.show();"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISeuxWnPio6T",
        "colab_type": "text"
      },
      "source": [
        "Let's try to calculate a sample student marks "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh-lqNsCivZp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "593688d8-cdd1-48f8-b644-c76c95b4b44c"
      },
      "source": [
        "hours = 9.25\n",
        "marks = c+m*hours\n",
        "print(\"A student studied for \", hours, \"and his/her predicted marks are \", marks)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A student studied for  9.25 and his/her predicted marks are  86.2561709325748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ZgmJMuNIYG",
        "colab_type": "text"
      },
      "source": [
        "Part 2: With Scikit-Learn library\n",
        "===\n",
        "\n",
        "In this section, we can simply use scikit learn library to perform linear regression with a two lines of code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyOvUFCcM_TI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "7c8072b8-da96-447e-e62b-b806f490aa94"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Load the student dataset\n",
        "data = pd.read_csv('http://bit.ly/w-data') # read the data\n",
        "\n",
        "X = data.Hours.values\n",
        "Y = data.Scores.values\n",
        "\n",
        "# Split the data into training/testing sets\n",
        "X_train = X[:-20].reshape(-1, 1)\n",
        "X_test = X[-20:].reshape(-1, 1)\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "y_train = Y[:-20]\n",
        "y_test = Y[-20:]\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions using the testing set\n",
        "y_pred = regr.predict(X_test)\n",
        "\n",
        "# The coefficients\n",
        "print('Coefficients: \\n', regr.coef_)\n",
        "# The mean squared error\n",
        "print('Mean squared error: %.2f'\n",
        "      % mean_squared_error(y_test, y_pred))\n",
        "# The coefficient of determination: 1 is perfect prediction\n",
        "print('Coefficient of determination: %.2f'\n",
        "      % r2_score(y_test, y_pred))\n",
        "\n",
        "# Plot outputs\n",
        "plt.scatter(X_test, y_test,  color='black')\n",
        "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: \n",
            " [9.07867315]\n",
            "Mean squared error: 107.55\n",
            "Coefficient of determination: 0.83\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpPHLNaDNMHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9bbb6ccc-808d-49c4-dbb3-9cd646e47c72"
      },
      "source": [
        "# sample student score\n",
        "hours = np.array([9.25])\n",
        "marks = regr.predict(hours.reshape(1, -1))\n",
        "print(\"A student studied for \", hours[0], \"and his/her predicted marks are \", marks[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A student studied for  9.25 and his/her predicted marks are  82.57897707537339\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}